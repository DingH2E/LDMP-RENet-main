DATA:
  data_root: 'dataset/MSD-Seg2/'
  train_list: 'dataset/data_list/train/fold_0_defective.txt'
  trainnom_list: 'dataset/data_list/train/fold_0_clean.txt'
  val_list: 'dataset/data_list/test/fold_0_defective.txt'
  valnom_list: 'dataset/data_list/test/fold_0_clean.txt'
  classes: 2


TRAIN:
  layers: 152 # 要改pretrained
  pretrained: False
  sync_bn: False
  train_h: 200
  train_w: 200
  val_size: 200
  scale_min: 0.9  # minimum random scale
  scale_max: 1.1 # maximum random scale
  rotate_min: -10  # minimum random rotate
  rotate_max: 10  # maximum random rotate
  ignore_label: 255
  padding_label: 255
  aux_weight: 1.0
  train_gpu: [1]
  workers: 2  # data loader workers
  batch_size: 2 # batch size for training
  batch_size_val: 1
  base_lr: 0.0005
  epochs: 200
  start_epoch: 0
  power: 0.9 # 0 means no decay
  momentum: 0.9
  weight_decay: 0.0001
  manual_seed: 1334 # 1334, 1258, 1355
  print_freq: 5
  save_freq: 5
  save_path: exp/Test5/fold0_VGG19/model  # model saved path
  weight:  # exp/CPA/fold0_VGG16/model/final.pth  # load weight for fine-tuning or testing
  resume:  # path to latest checkpoint (default: none)
  evaluate: True
  split: 0
  shot: 1
  vgg: False # use vgg as backbone or not
  vgg_layers: 18
  ppm_scales: [60, 30, 15, 8]
  fix_random_seed_val: True
  warmup: False
  resized_val: True
  ori_resize: True  # use original label for evaluation
  normal: 1
  is_nom: True
  FPN : False
  pyramid : False
  align : False
  zoom_factor : 8
  data_set : " "
  train_iter: 10
  eval_iter: 5
  viz: True

  aux_weight1: 1.0
  aux_weight2: 0.2
  low_fea: 'layer2'  # low_fea for computing the Gram matrix
  kshot_trans_dim: 2 # K-shot dimensionality reduction
  merge: 'final'     # fusion scheme for GFSS ('base' Eq(S1) | 'final' Eq(18) )
  merge_tau: 0.9     # fusion threshold tau

  cls_type: "Novel"
  distributed: True